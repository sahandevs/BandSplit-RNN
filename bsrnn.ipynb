{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741a4d6f-e587-4f57-8a1d-1c54412d69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import IPython.display as idp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ee4ca1-ac3e-40d7-845a-23f6c4f625ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize=False\n",
    "# Feature gate: Overtones Splits\n",
    "fg_generic_bands = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e425c21-aa1a-419c-904e-c68e9a683582",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1) Input and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16cbc51-70f7-41c4-be4c-cb6a7c5debd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "\n",
    "sample_rate = 44100 # \n",
    "\n",
    "def show_idp_audio(waveform):\n",
    "    n = 14\n",
    "    return idp.display(idp.Audio(waveform[(3 * n) * sample_rate:(3 * (n + 1)) * sample_rate], rate=sample_rate))\n",
    "\n",
    "def load_audio(path, visualize=False):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    # Convert everthing to mono channel for simplicity\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        # waveform is now a vector \n",
    "    # Resample everything to 44.1khz for simplicity\n",
    "    resampler = T.Resample(sr, sample_rate, dtype=waveform.dtype)\n",
    "    waveform = resampler(waveform)\n",
    "    \n",
    "    if visualize:\n",
    "        # samplerate = 1/t\n",
    "        # display the first 3 seconds\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "if visualize:\n",
    "    sample_waveform = load_audio(\"mixture.wav\", visualize=True)\n",
    "\n",
    "    sample_waveform.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45db49d1-7007-4b1f-a9d0-e4a68dfb773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_normalize(waveform, target_rms):\n",
    "    current_rms = torch.sqrt(torch.mean(waveform**2))\n",
    "    gain_factor = target_rms / (current_rms + 1e-10)\n",
    "    normalized_waveform = waveform * gain_factor\n",
    "    return normalized_waveform, gain_factor\n",
    "\n",
    "def rms_denormalize(normalized_waveform, gain_factor):\n",
    "    inverse_gain = 1 / gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def peak_normalize(waveform, target_peak):\n",
    "    peak_value = torch.max(torch.abs(waveform))\n",
    "    peak_gain_factor = target_peak / (peak_value + 1e-10)\n",
    "    normalized_waveform = waveform * peak_gain_factor\n",
    "    return normalized_waveform, peak_gain_factor\n",
    "\n",
    "def peak_denormalize(normalized_waveform, peak_gain_factor):\n",
    "    inverse_peak_gain = 1 / peak_gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_peak_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def inspect_waveform(waveform):\n",
    "    transform = T.Loudness(sample_rate)\n",
    "    return f\"LKFS:{transform(waveform.unsqueeze(0))} max: {waveform.max()} min: {waveform.min()} avg: {waveform.mean()}\"\n",
    "\n",
    "def normalize_waveform(waveform, visualize=False):\n",
    "    \"\"\" rms -> peak \"\"\"\n",
    "    # target rms can be anything. the important part here\n",
    "    # is to be constant for all kind of songs\n",
    "\n",
    "    if visualize:\n",
    "        print(\"original: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "\n",
    "    normalized_waveform, gain_factor = rms_normalize(waveform, target_rms=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "\n",
    "    # setting target peak to 1.0 forces the values between -1.0 < y < 1.0\n",
    "    normalized_waveform, peak_gain_factor = peak_normalize(normalized_waveform, target_peak=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "    \n",
    "    return normalized_waveform, gain_factor, peak_gain_factor\n",
    "\n",
    "def de_normalize_waveform(waveform, gain_factor, peak_gain_factor, visualize=False):\n",
    "    if visualize:\n",
    "        print(\"de_normalize_waveform: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    waveform = peak_denormalize(waveform, peak_gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    waveform = rms_denormalize(waveform, gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "if visualize:\n",
    "    normal_waveform, gain_factor, peak_gain_factor = normalize_waveform(sample_waveform, visualize=True)\n",
    "    _ = de_normalize_waveform(normal_waveform, gain_factor, peak_gain_factor, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7787ec7-063b-47f3-9549-578fc962cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_in_seconds = 1\n",
    "chunk_size = chunk_size_in_seconds * sample_rate\n",
    "\n",
    "def split(waveform, visualize=False):\n",
    "    # we have a vector by length n and we want to split it to even chunks by length of\n",
    "    # chunk_size\n",
    "    padding_length = (chunk_size - waveform.shape[0] % chunk_size) % chunk_size\n",
    "    waveform = nn.functional.pad(waveform, (0, padding_length), 'constant', 0)\n",
    "    # -1 means automatically infer based on other dims\n",
    "    chunked_waveform = waveform.view(-1, chunk_size)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(16, 4))\n",
    "        subfigs = fig.subfigures(2, 1).flat\n",
    "        \n",
    "        # first 3 chunk_size of waveform\n",
    "        w = waveform[:3 * chunk_size].detach().numpy()\n",
    "        ylim = [w.max() * 1.1, w.min() * 1.1]\n",
    "        def time_axis(start, duration):\n",
    "            return torch.arange(start * sample_rate, (duration + start) * sample_rate) / sample_rate\n",
    "        axes = subfigs[0].subplots(1, 1)\n",
    "        axes.plot(time_axis(0, 3), w, linewidth=0.3)\n",
    "        axes.set_xlabel(\"time [s] for first 3 seconds\")\n",
    "        axes.set_ylim(ylim)\n",
    "        \n",
    "        # first 4 chunks + last chunk\n",
    "        axes = subfigs[1].subplots(1, 5)\n",
    "        for i, chunk in enumerate([0, 1, 3, 4, chunked_waveform.shape[0] - 1]): \n",
    "            axes[i].plot(time_axis(0, chunk_size_in_seconds), chunked_waveform[chunk], linewidth=0.3)\n",
    "            axes[i].set_title(f\"chunk {chunk}\")\n",
    "            axes[i].set_ylim(ylim)\n",
    "        \n",
    "    return chunked_waveform, padding_length\n",
    "\n",
    "def merge(chunks, padding_length):\n",
    "    merged_waveform = torch.cat([torch.flatten(x) for x in chunks])\n",
    "    return merged_waveform[:-padding_length]\n",
    "\n",
    "if visualize:\n",
    "    sample_waveform_chunks, padding_length = split(normal_waveform, visualize=True)\n",
    "\n",
    "    assert sample_waveform_chunks.shape[1] == chunk_size\n",
    "\n",
    "    sample_merged = merge(sample_waveform_chunks, padding_length)\n",
    "\n",
    "    assert sample_merged.shape == normal_waveform.shape\n",
    "    assert torch.all(sample_merged == normal_waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3f9132-958f-4704-8ad9-3a22c4138b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "win_length = n_fft\n",
    "hop_length = win_length // 4\n",
    "\n",
    "\n",
    "def visualize_spectogram(chunk, chunk_stft, title='Spectogram'):\n",
    "    import librosa\n",
    "    fig, axis = plt.subplots(2, 1, figsize=(16, 5))\n",
    "    noverlap = win_length - hop_length\n",
    "    axis[0].imshow(librosa.power_to_db(chunk_stft.abs().detach().numpy() ** 2), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    axis[0].set_yscale(\"symlog\")\n",
    "    axis[0].set_title(title)\n",
    "    if chunk is not None:\n",
    "        axis[1].plot(chunk, linewidth=0.5)\n",
    "        axis[1].grid(True)\n",
    "        axis[1].set_xlim([0, len(chunk)])\n",
    "\n",
    "def to_spectogram():\n",
    "    transform_spectogram = T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                         window_fn=torch.hamming_window, power=None)\n",
    "    def inner(chunk, visualize=False, title=''):\n",
    "        chunk_stft = transform_spectogram(chunk)\n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk, chunk_stft, title)\n",
    "\n",
    "        return chunk_stft\n",
    "    return inner\n",
    "\n",
    "if visualize:\n",
    "    print(sample_waveform_chunks[1].shape)\n",
    "    chunk_stft = to_spectogram()(sample_waveform_chunks[1], visualize=True)\n",
    "    chunk_stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5e3f90-057c-48b1-8340-6b158236836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vis:\n",
    "    def visualize(self, input):\n",
    "        from torchview import draw_graph\n",
    "        y = self(input)\n",
    "        x = draw_graph(self, input_data=input, device='meta', roll=True)\n",
    "        print(f\"--{input.shape}-->f(x)--{y.shape}-->\")\n",
    "        file = x.visual_graph.render(self._get_name())\n",
    "        display(idp.FileLink(\"./\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899ea2b1-dcce-48d8-a01e-5f8e9919bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_microtone_name(semitones_from_A4, divisions_per_octave):\n",
    "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "    microtone_index = int((semitones_from_A4 + 9) * divisions_per_octave / 12) % divisions_per_octave\n",
    "    octave = int((semitones_from_A4 + 9) // 12)\n",
    "    note_index = microtone_index // (divisions_per_octave // 12)\n",
    "    microtone_suffix = f\"+{microtone_index % (divisions_per_octave // 12)}\"\n",
    "    return notes[note_index] + (microtone_suffix if microtone_suffix != \"+0\" else \"\") + str(octave)\n",
    "\n",
    "def microtonal_notes(divisions_per_octave):\n",
    "    A4_freq = 440.0\n",
    "    min_freq = 20.0\n",
    "    max_freq = 20000.0\n",
    "    notes = []\n",
    "    freqs = []\n",
    "    current_freq = min_freq\n",
    "    while current_freq <= max_freq:\n",
    "        semitones_from_A4 = 12 * np.log2(current_freq / A4_freq)\n",
    "        nearest_microtone = round(semitones_from_A4 * divisions_per_octave / 12)\n",
    "        nearest_freq = A4_freq * (2 ** (nearest_microtone / divisions_per_octave))\n",
    "\n",
    "        # Check if the frequency is a microtonal (not a standard semitone)\n",
    "        if nearest_microtone % (divisions_per_octave // 12) != 0:\n",
    "            note_name = get_microtone_name(nearest_microtone / (divisions_per_octave / 12), divisions_per_octave)\n",
    "            notes.append(note_name)\n",
    "            freqs.append(nearest_freq)\n",
    "\n",
    "        # Move to the next microtone\n",
    "        current_freq = A4_freq * (2 ** ((nearest_microtone + 1) / divisions_per_octave))\n",
    "    return (notes, freqs)\n",
    "\n",
    "def plot_custom_labeled_attention_distribution(splits):\n",
    "    start_freq = 0\n",
    "    events = []\n",
    "    for end_freq, step_size in splits:\n",
    "        while start_freq < end_freq:\n",
    "            start_freq += step_size\n",
    "            events.append(start_freq)\n",
    "\n",
    "    notes, positions = microtonal_notes(24)\n",
    "    print(len(events))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks(positions, notes, rotation=90, fontsize=9)\n",
    "    plt.eventplot(events, orientation='horizontal', colors='b')\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "if visualize:\n",
    "    plot_custom_labeled_attention_distribution(splits_v7)\n",
    "\n",
    "def evenly_skip_elements(input_list, k):\n",
    "    \"\"\"\n",
    "    Reduce the size of the input list to 'k' by skipping elements evenly.\n",
    "\n",
    "    :param input_list: The original list.\n",
    "    :param k: The desired size of the new list, must be smaller or equal to the size of input_list.\n",
    "    :return: A new list of size 'k'.\n",
    "    \"\"\"\n",
    "    if k > len(input_list):\n",
    "        raise ValueError(\"k must be smaller or equal to the size of the input list\")\n",
    "\n",
    "    # Calculate the step for even skipping\n",
    "    step = len(input_list) / k\n",
    "\n",
    "    # Generate the new list\n",
    "    new_list = [input_list[int(i * step)] for i in range(k)]\n",
    "\n",
    "    return new_list\n",
    "\n",
    "def create_evenly_distributed_splits(num_splits):\n",
    "    _, freqs = microtonal_notes(24)\n",
    "    splits = []\n",
    "    last_freq = 0\n",
    "    for freq in evenly_skip_elements(freqs, num_splits):\n",
    "        splits.append((freq, freq - last_freq))\n",
    "        last_freq = freq\n",
    "    return splits\n",
    "    \n",
    "\n",
    "splits_generic = create_evenly_distributed_splits(41)\n",
    "if visualize:\n",
    "    plot_custom_labeled_attention_distribution(splits_generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8adf8d8e-eda8-4354-9256-df3786f80e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers are exctracted from the paper\n",
    "splits_v7 = [\n",
    "   # below 1kh, bandwidth 100hz\n",
    "   (1000, 100),\n",
    "   # above 1kh and below 4khz, bandwidth 250hz\n",
    "   (4000, 250),\n",
    "   (8000, 500),\n",
    "   (16000, 1000),\n",
    "   (20000, 2000),\n",
    "]\n",
    "\n",
    "temporal_dim = int(np.ceil(chunk_size / T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length).hop_length))\n",
    "feature_dim = 128 // 4\n",
    "\n",
    "# Module 1\n",
    "class BandSplit(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, splits=splits_generic if fg_generic_bands else splits_v7, fully_connected_out=feature_dim):\n",
    "        super(BandSplit, self).__init__()\n",
    "        \n",
    "        \n",
    "        #### Make splits\n",
    "        # convert fft to freq\n",
    "        freqs = sample_rate * torch.fft.fftfreq(n_fft)[:n_fft // 2 + 1]\n",
    "        freqs[-1] = sample_rate // 2\n",
    "        indices = []\n",
    "        start_freq, start_index = 0, 0\n",
    "        for end_freq, step in splits:\n",
    "            bands = torch.arange(start_freq + step, end_freq + step, step)\n",
    "            start_freq = end_freq\n",
    "            for band in bands:\n",
    "                end_index = freqs[freqs < band].shape[0]\n",
    "                if end_index != start_index or not fg_generic_bands:\n",
    "                    indices.append((start_index, end_index))\n",
    "                start_index = end_index\n",
    "        indices.append((start_index, freqs.shape[0]))\n",
    "        self.band_indices = indices\n",
    "        print(self.band_indices)\n",
    "        self.fully_connected_out = fully_connected_out\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.LayerNorm([(band_end - band_start) * 2, temporal_dim])\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "        \n",
    "        self.layer_fcs =  nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.Linear((band_end - band_start) * 2, fully_connected_out)\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "\n",
    "    def forward(self, chunk_ftt):\n",
    "        batch_size = chunk_ftt.size(0)\n",
    "        stack = []\n",
    "        # TODO: can i vectorize this loop?\n",
    "        for i, (band_start, band_end) in enumerate(self.band_indices):\n",
    "            band = chunk_ftt[:, band_start:band_end, :]\n",
    "            # band is shape of (B, F, T)\n",
    "            band = torch.view_as_real(band) # (B, F, T, 2)\n",
    "            # convert to (B, 2, F, T) to be able to feed it to the norm\n",
    "            band = band.permute(0, 3, 1, 2)\n",
    "            \n",
    "            # norm is (..., F, T) and fc is (Fxfully_connected_out)\n",
    "            # we should make norm (..., T, F) in order to feed it to the fc\n",
    "            band = band.reshape(batch_size, -1, band.size(-1)) # -1 = T\n",
    "            norm = self.layer_norms[i](band)\n",
    "            \n",
    "            norm = norm.transpose(-1, -2).contiguous()\n",
    "            fc_y = self.layer_fcs[i](norm)\n",
    "            \n",
    "            stack.append(fc_y)\n",
    "        return torch.stack(stack, dim=1)\n",
    "\n",
    "if visualize:\n",
    "    bandsplit_layer = BandSplit()\n",
    "    bandsplit_y = bandsplit_layer(chunk_stft.unsqueeze(0))\n",
    "    bandsplit_layer.visualize(chunk_stft.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca7dfeea-f1c3-41a7-a4ff-06b0f0e39e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_dim_size = input_dim_size\n",
    "        # paper specified group norm\n",
    "        self.norm = nn.ModuleList([nn.GroupNorm(self.input_dim_size, self.input_dim_size) for _ in range(2)])\n",
    "        self.blstm = nn.ModuleList([nn.LSTM(self.input_dim_size, self.input_dim_size, bidirectional=True, batch_first=True) for _ in range(2)])\n",
    "        self.fc = nn.ModuleList([nn.Linear(self.input_dim_size * 2, self.input_dim_size) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input is b, bands(K), temporal_dim(t), input_dim_size\n",
    "        \n",
    "        \n",
    "        # First loops converts the shape to [B, T, K, N]\n",
    "        # and the second loop converts it back to [B, K, T, N]\n",
    "        for i in range(2):\n",
    "            B, K, T, N = x.shape\n",
    "            out = x.view(B * K, T, N)\n",
    "            out = self.norm[i](out.transpose(-1, -2)).transpose(-1, -2)\n",
    "            out = self.blstm[i](out)[0]\n",
    "            out = self.fc[i](out)\n",
    "            x = out.view(B, K, T, N) + x\n",
    "            x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        return x\n",
    "\n",
    "num_blstm_layers=24 // 2\n",
    "\n",
    "class BandSequence(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, input_dim_size, num_layers=num_blstm_layers):\n",
    "        super(BandSequence, self).__init__()\n",
    "        self.rnns = nn.Sequential(*[RNN(input_dim_size=input_dim_size) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (bands, temporal_dim, fc_out)\n",
    "        return self.rnns(x)\n",
    "\n",
    "if visualize:\n",
    "    bandsequence_layer = BandSequence(input_dim_size=bandsplit_layer.fully_connected_out)\n",
    "    bandsequence_y = bandsequence_layer(bandsplit_y)\n",
    "    bandsequence_layer.visualize(bandsplit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9fe8f3d-b9ff-4e24-b532-bbbdfd45b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MaskEstimation(nn.Module, Vis):\n",
    "    def __init__(self, band_indices, fully_connected_out):\n",
    "        super(MaskEstimation, self).__init__()\n",
    "        \n",
    "        max_indice_diff = max([e - s for s, e in band_indices])\n",
    "        num_hiddens = lambda e, s: 3 * (max_indice_diff - (e - s) + 1)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm([temporal_dim, fully_connected_out]),\n",
    "                nn.Linear(fully_connected_out, num_hiddens(e, s)),\n",
    "                nn.Tanh(),\n",
    "                # double the output dim to use in GLU\n",
    "                # the extra *2 is for returning as complex\n",
    "                nn.Linear(num_hiddens(e, s), (e - s) * 2 * 2),\n",
    "                nn.GLU()\n",
    "            )\n",
    "            for s, e in band_indices\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (b, k, temporal_dim, fc_out)\n",
    "        parts = []\n",
    "        for i in range(x.shape[1]):\n",
    "            y = self.layers[i](x[:, i]).contiguous()\n",
    "            B, T, F = y.shape\n",
    "            y = y.permute(0, 2, 1).contiguous() # B F T\n",
    "            # basically halve the freq dim and use it for phasee\n",
    "            y = y.view(B, 2, F // 2, T) # (B, 2, F, T)\n",
    "            y = y.permute(0, 2, 3, 1) # (B, F, T, 2)\n",
    "            y = torch.view_as_complex(y.contiguous())\n",
    "            \n",
    "            parts.append(y)\n",
    "        \n",
    "        # (b, f, t)\n",
    "        return torch.cat(parts, dim=-2)\n",
    "\n",
    "    \n",
    "if visualize:   \n",
    "    mask_layer = MaskEstimation(band_indices=bandsplit_layer.band_indices, fully_connected_out=bandsplit_layer.fully_connected_out)\n",
    "    mask_y = mask_layer(bandsequence_y)\n",
    "    mask_layer.visualize(bandsequence_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "848d0886-e194-4a72-8a81-b27554be18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSRNN(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BSRNN, self).__init__()\n",
    "        \n",
    "        self.split = BandSplit()\n",
    "        self.sequence = BandSequence(input_dim_size=self.split.fully_connected_out)\n",
    "        self.mask = MaskEstimation(band_indices=self.split.band_indices, fully_connected_out=self.split.fully_connected_out)\n",
    "\n",
    "    def forward(self, chunk_fft):\n",
    "        \n",
    "        mean = chunk_fft.mean(dim=(1, 2), keepdim=True)\n",
    "        std = chunk_fft.std(dim=(1, 2), keepdim=True)\n",
    "        chunk_fft = (chunk_fft - mean) / (std + 1e-5)\n",
    "        \n",
    "        y = self.split(chunk_fft)\n",
    "        y = self.sequence(y)\n",
    "        mask = self.mask(y)\n",
    "        \n",
    "        mask = mask * std + mean\n",
    "\n",
    "        return mask\n",
    "\n",
    "if visualize:\n",
    "    bsrnn = BSRNN().cuda()\n",
    "    bsrnn_y = bsrnn(chunk_stft.unsqueeze(0).cuda())\n",
    "    bsrnn.visualize(chunk_stft.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ac4f830-f48c-4900-903b-593ab23c4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_spectogram():\n",
    "    # We are using GriffinLim to ensure the output size\n",
    "    transform_inv_spectogram = T.InverseSpectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                                    window_fn=torch.hamming_window)\n",
    "\n",
    "    def inner(chunk_stft, visualize=False):\n",
    "        chunk = transform_inv_spectogram(chunk_stft)\n",
    "    \n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk.detach().numpy(), chunk_stft)\n",
    "\n",
    "        return chunk\n",
    "    return inner\n",
    "\n",
    "if visualize:\n",
    "    print(bsrnn_y.shape)\n",
    "    masked_complex = chunk_stft * bsrnn_y[0].cpu()\n",
    "\n",
    "    chunk_y = from_spectogram()(masked_complex, visualize=True)\n",
    "    chunk_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf3b1032-7bc6-40f9-9745-854c3be034b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize and False:\n",
    "    chunk_x = de_normalize_waveform(sample_waveform_chunks[1], gain_factor, peak_gain_factor)\n",
    "    chunk_y = de_normalize_waveform(chunk_y, gain_factor, peak_gain_factor)\n",
    "\n",
    "    print(\"In:\")\n",
    "    show_idp_audio(chunk_x)\n",
    "    print(\"Out:\")\n",
    "    show_idp_audio(chunk_y.detach().numpy())\n",
    "    print(chunk_y.shape)\n",
    "    chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05ed9801-0fde-4110-a40f-95b20d787857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27095"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b72ccde-384a-40da-b144-1206e527d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Everything Together! audio in, audio out!\n",
    "\n",
    "\n",
    "class MSSBandSplitRNN(nn.Module, Vis):\n",
    "    def __init__(self):\n",
    "        super(MSSBandSplitRNN, self).__init__()\n",
    "        self.to_spectogram = to_spectogram()\n",
    "        self.from_spectogram = from_spectogram()\n",
    "        self.bsrnn = BSRNN()\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        \"\"\" Waveform in -> Waveform out :) \"\"\"\n",
    "        \n",
    "        # 1) normalize\n",
    "        # 2) split\n",
    "        # 3) feed to bsrnn\n",
    "        # 4) convert spectogram to audio\n",
    "        # 5) merge all splits\n",
    "        # 6) de-normalize\n",
    "        \n",
    "        normal_waveform, gain_factor, peak_gain_factor = normalize_waveform(waveform)\n",
    "        splits, padding_length = split(normal_waveform)\n",
    "        masked_splits = [() for _ in range(len(splits))]\n",
    "        for i, x_split in enumerate(splits):\n",
    "            split_stft = self.to_spectogram(x_split)\n",
    "            mask = self.bsrnn(split_stft.unsqueeze(0))[0]\n",
    "            \n",
    "            masked_complex = mask\n",
    "            \n",
    "            wave = self.from_spectogram(masked_complex)\n",
    "            masked_splits[i] = wave\n",
    "        \n",
    "        masked_waveform = merge(masked_splits, padding_length)\n",
    "        y = de_normalize_waveform(masked_waveform, gain_factor, peak_gain_factor)\n",
    "        return y\n",
    "\n",
    "if visualize:\n",
    "    torch.set_default_device('cuda')\n",
    "    with torch.no_grad():\n",
    "        model = MSSBandSplitRNN()\n",
    "        y = model(sample_waveform.cuda())\n",
    "\n",
    "\n",
    "    print(\"In:\")\n",
    "    show_idp_audio(sample_waveform)\n",
    "    print(\"Out:\")\n",
    "    show_idp_audio(y.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004c354-c93f-4d13-a326-3197b0b8a38f",
   "metadata": {},
   "source": [
    "# 2) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75190bcb-729e-4b92-ba27-f8b71421137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mae_stft_real = nn.L1Loss()\n",
    "        self.mae_stft_imag = nn.L1Loss()\n",
    "        self.mae_inv_stft  = nn.L1Loss()\n",
    "    \n",
    "    def forward(self, pred_stft, target_stft,  pred_inv_stft, target_inv_stft):\n",
    "        loss_r = self.mae_stft_real(pred_stft.real, target_stft.real)\n",
    "        loss_i = self.mae_stft_imag(pred_stft.imag, target_stft.imag)\n",
    "        loss_t = self.mae_inv_stft(pred_inv_stft, target_inv_stft)\n",
    "        loss = loss_r + loss_i + loss_t\n",
    "        return loss\n",
    "\n",
    "def compute_usdr(pred, target, delta = 1e-7):\n",
    "    if pred.shape[0] < target.shape[0]:\n",
    "        padding = target.shape[0] - pred.shape[0]\n",
    "        pred = torch.nn.functional.pad(pred, (0, padding), \"constant\", 0)\n",
    "    num = torch.sum(torch.square(target))\n",
    "    den = torch.sum(torch.square(target - pred))\n",
    "    num += delta\n",
    "    den += delta\n",
    "    usdr = 10 * torch.log10(num / den)\n",
    "    return usdr.mean()\n",
    "\n",
    "if visualize and False:\n",
    "    torch.set_default_device('cpu')\n",
    "    target_wf = load_audio(\"drums.wav\")\n",
    "    normal_target_wf, gain_factor, peak_gain_factor = normalize_waveform(target_wf)\n",
    "    target_wf_chunks, padding_length = split(normal_target_wf)\n",
    "    stft = to_spectogram()\n",
    "    inv_stft = from_spectogram()\n",
    "    print(\"target:\")\n",
    "    show_idp_audio(target_wf_chunks[1])\n",
    "    target_stft = stft(target_wf_chunks[1], visualize=True, title=\"Target\")\n",
    "    print(\"input:\")\n",
    "    show_idp_audio(sample_waveform_chunks[1])\n",
    "    sample_stft = stft(sample_waveform_chunks[1], visualize=True, title=\"Input\")\n",
    "\n",
    "    # x * mask = target_stft / x\n",
    "    # f(x) = stft - \n",
    "\n",
    "    mask_stft = target_stft / sample_stft\n",
    "    visualize_spectogram(inv_stft(mask_stft), mask_stft, title=\"Mask stft\")\n",
    "    print(\"Mask:\")\n",
    "    show_idp_audio(inv_stft(mask_stft))\n",
    "    target_y = sample_stft * mask_stft\n",
    "    print(\"Target_y: \")\n",
    "    show_idp_audio(inv_stft(target_y))\n",
    "    visualize_spectogram(inv_stft(target_y), target_y, title=\"Target_y stft calc\")\n",
    "\n",
    "\n",
    "    loss_fn = CustomLoss()\n",
    "    loss = loss_fn.forward(target_y, target_stft, inv_stft(target_y), inv_stft(target_stft))\n",
    "    print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e72fc97f-3d1c-4faa-8f6f-ec06f611d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dir_=\"/home/sahand/BandSplit-RNN/musdb18hq/\", validation=False):\n",
    "        super(Dataset, self).__init__()\n",
    "        path = dir_ + (\"test\" if validation else \"train\")\n",
    "        print(path)\n",
    "        self.files = [entry for entry in os.scandir(path) if entry.is_dir()]\n",
    "        random.shuffle(self.files)\n",
    "    \n",
    "    def iterator(self):\n",
    "        torch.set_default_device('cpu')\n",
    "        to_stft = to_spectogram()\n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            d = self.files[i]\n",
    "            mixture = f\"{d.path}/mixture.wav\"\n",
    "            target = f\"{d.path}/drums.wav\"\n",
    "\n",
    "            normal_mix, _, _ = normalize_waveform(load_audio(mixture))\n",
    "            normal_target, _, _ = normalize_waveform(load_audio(target))\n",
    "\n",
    "            normal_mix, _ = split(normal_mix)\n",
    "            normal_target, _ = split(normal_target)\n",
    "\n",
    "            for mix, target in zip(normal_mix, normal_target):\n",
    "                mix_stft = to_stft(mix)\n",
    "                target_stft = to_stft(target)\n",
    "                # Accumulate STFTs in the batch\n",
    "                yield (mix_stft, target_stft)\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is not None:\n",
    "            total_files = len(self.files)\n",
    "            per_worker = int(math.ceil(total_files / float(worker_info.num_workers)))\n",
    "            self.start_index = worker_info.id * per_worker\n",
    "            self.end_index = min(self.start_index + per_worker, total_files)\n",
    "        else:\n",
    "            self.start_index = 0\n",
    "            self.end_index = len(self.files)\n",
    "\n",
    "        return iter(self.iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a75952a2-8af0-465a-8db3-9259e55768cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bcf93d8-3df8-4651-8d0f-23a4d9294ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sahand/BandSplit-RNN/musdb18hq/train\n",
      "/home/sahand/BandSplit-RNN/musdb18hq/test\n",
      "[(0, 5), (5, 10), (10, 14), (14, 19), (19, 24), (24, 28), (28, 33), (33, 38), (38, 42), (42, 47), (47, 59), (59, 70), (70, 82), (82, 93), (93, 105), (105, 117), (117, 128), (128, 140), (140, 151), (151, 163), (163, 175), (175, 186), (186, 209), (209, 233), (233, 256), (256, 279), (279, 302), (302, 326), (326, 349), (349, 372), (372, 418), (418, 465), (465, 511), (511, 558), (558, 604), (604, 651), (651, 697), (697, 744), (744, 836), (836, 929), (929, 1025)]\n"
     ]
    }
   ],
   "source": [
    "batch_size=95\n",
    "clip_grad_norm=5\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(validation=False), num_workers=1, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                          persistent_workers=True)\n",
    "val_loader   = torch.utils.data.DataLoader(Dataset(validation=True), num_workers=1, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                          persistent_workers=True)\n",
    "\n",
    "\n",
    "model = BSRNN().to('cuda')\n",
    "# model = torch.load(\"./drums-reversed-mask/bsrnn-102-0.031533900648355484.pt\")\n",
    "import datetime\n",
    "\n",
    "name = f\"generic-splits\"\n",
    "prefix=f\"./train-logs/{name}-{datetime.datetime.now()}\"\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c1f2310-9d39-4b67-aef8-dbe262bd1ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000816"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d912587e-ca08-4eb1-be90-52c7a20112b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, Checkpoint, DiskSaver, global_step_from_engine\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine, ProgressBar, TensorboardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3db422f6-b9d6-4755-9fb1-3e1eff52ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = CustomLoss()\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "inv_stft_gpu = from_spectogram()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    mix_stft, mask_stft = batch\n",
    "    mix_stft, mask_stft = mix_stft.to('cuda'), mask_stft.to('cuda')\n",
    "    y_mask = model(mix_stft)\n",
    "    inv_y_mask = inv_stft_gpu(y_mask)\n",
    "    inv_mask_stft = inv_stft_gpu(mask_stft)\n",
    "    loss = loss_fn(y_mask, mask_stft, inv_y_mask, inv_mask_stft)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "    optimizer.step()\n",
    "    \n",
    "    usdr_value = compute_usdr(inv_y_mask, inv_mask_stft).item()\n",
    "    return {'loss': loss.item(), 'usdr': usdr_value}\n",
    "\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "running_avg_usdr = RunningAverage(output_transform=lambda x: x['usdr'])\n",
    "running_avg_usdr.attach(trainer, 'running_avg_usdr')\n",
    "running_avg_loss = RunningAverage(output_transform=lambda x: x['loss'])\n",
    "running_avg_loss.attach(trainer, 'running_avg_loss')\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir=f\"{prefix}/tb\")\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda x: {\"running_avg_loss\": trainer.state.metrics['running_avg_loss'], \n",
    "                                \"running_avg_usdr\": trainer.state.metrics['running_avg_usdr']}\n",
    ")\n",
    "\n",
    "\n",
    "# Model Checkpointing\n",
    "to_save = {\n",
    "    'trainer': trainer,\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'running_avg_usdr': running_avg_usdr,\n",
    "    'running_avg_loss': running_avg_loss\n",
    "}\n",
    "checkpoint_handler = Checkpoint(to_save, DiskSaver(f'{prefix}/models', create_dir=True), n_saved=10, global_step_transform=global_step_from_engine(trainer))\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler)\n",
    "\n",
    "# Resume Training\n",
    "checkpoint_fp = 'checkpoints/checkpoint.ckpt'\n",
    "if os.path.isfile(checkpoint_fp):\n",
    "    checkpoint = torch.load(checkpoint_fp)\n",
    "    Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "# Progress Bar\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=['running_avg_loss', 'running_avg_usdr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d446fd-2217-4695-9973-5351c52c8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "# Run Training\n",
    "trainer.run(train_loader, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a27f7daf-8253-4bae-b64e-c294eb973fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02765b39e3a94b9e976056f58b7ae5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 4.173307912659941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 131\n",
       "\tepoch: 1\n",
       "\tepoch_length: 131\n",
       "\tmax_epochs: 1\n",
       "\toutput: <class 'NoneType'>\n",
       "\tbatch: <class 'NoneType'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval\n",
    "\n",
    "checkpoint_fp = './train-logs/baseline-2023-12-21 14:05:22.129601/checkpoint_58.pt'\n",
    "if os.path.isfile(checkpoint_fp):\n",
    "    checkpoint = torch.load(checkpoint_fp)\n",
    "    Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mix_stft, mask_stft = batch\n",
    "        mix_stft, mask_stft = mix_stft.to('cuda'), mask_stft.to('cuda')\n",
    "        y_mask = model(mix_stft)\n",
    "        inv_y_mask = inv_stft_gpu(y_mask)\n",
    "        inv_mask_stft = inv_stft_gpu(mask_stft)\n",
    "        usdr_value = compute_usdr(inv_y_mask, inv_mask_stft).item()\n",
    "        return {'usdr': usdr_value}\n",
    "\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "running_avg_usdr = RunningAverage(output_transform=lambda x: x['usdr'])\n",
    "running_avg_usdr.attach(evaluator, 'running_avg_usdr')\n",
    "\n",
    "@evaluator.on(Events.COMPLETED)\n",
    "def log_results(engine):\n",
    "    print(f\"Test Results - Avg usdr: {engine.state.metrics['running_avg_usdr']}\")\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(evaluator, metric_names=['running_avg_usdr'])\n",
    "\n",
    "evaluator.run(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b06388-8355-493e-a93f-a4997be11436",
   "metadata": {},
   "source": [
    "## Evaluation Log\n",
    "\n",
    "- `./train-logs/generic-splits-2023-12-22 17:01:33.861454/models/checkpoint_158.pt`\n",
    "\n",
    "Test Results - Avg usdr: 4.249491467122149\n",
    "\n",
    "- './train-logs/baseline-2023-12-21 14:05:22.129601/checkpoint_58.pt'\n",
    "\n",
    "Test Results - Avg usdr: 4.173307912659941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b47324-65d1-40c1-9e44-daefaaa01642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34477a-78c7-42c5-9e8a-1e7af36bd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda')\n",
    "m = MSSBandSplitRNN()\n",
    "model.eval()\n",
    "m.bsrnn = model\n",
    "mixture_wav = load_audio(\"mixture.wav\")\n",
    "target_wav = load_audio(\"drums.wav\")\n",
    "with torch.no_grad():\n",
    "    y = m(mixture_wav.cuda())\n",
    "show_idp_audio(mixture_wav)\n",
    "show_idp_audio(y.cpu().detach().numpy())\n",
    "show_idp_audio(target_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8d3a9-fca6-4926-8443-3fdc73278204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "import glob\n",
    "models = list(glob.glob(\"*.pt\"))\n",
    "models = sorted(models, key=lambda x: int(x.split(\"-\")[1]))\n",
    "mixture_wav = load_audio(\"mixture.wav\")\n",
    "target_wav = load_audio(\"drums.wav\")\n",
    "print(\"mixture:\")\n",
    "show_idp_audio(mixture_wav)\n",
    "print(\"target:\")\n",
    "show_idp_audio(target_wav)\n",
    "\n",
    "dw = None\n",
    "for i, model_path in enumerate(models):\n",
    "    if i % 5 != 0:\n",
    "        continue\n",
    "    model_bsrnn = torch.load(model_path, map_location=\"cuda\")\n",
    "    m = MSSBandSplitRNN()\n",
    "    m.bsrnn = model_bsrnn\n",
    "    w = torch.cat([t.view(-1) for t in list(m.parameters())])\n",
    "    if dw is None:\n",
    "        dw = nn.L1Loss()(torch.zeros_like(w), w)\n",
    "    else:\n",
    "        dw = nn.L1Loss()(dw, w)\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            y = m(mixture_wav.cuda())\n",
    "        usdr = compute_usdr(y, target_wav.cuda())\n",
    "        print(f\"{model_path} △w={dw} usdr={usdr}: \")\n",
    "        \n",
    "        show_idp_audio(y.cpu().detach().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bsrnn]",
   "language": "python",
   "name": "conda-env-bsrnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
