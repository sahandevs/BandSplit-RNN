{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513c29eb-c30a-43ae-a380-bfc37e569c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))\n",
    "\n",
    "#~~~~Flags, options and hyperparameters~~~~\n",
    "\n",
    "# Feature gate: Overtones Splits\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='bsrnn')\n",
    "\n",
    "parser.add_argument('--sample_rate', type=int, default=44100)\n",
    "parser.add_argument('--generic_bands', type=str, default=\"N\")\n",
    "parser.add_argument('--chunk_size_in_seconds', type=int, default=1)\n",
    "parser.add_argument('--n_fft', type=int, default=2048)\n",
    "parser.add_argument('--feature_dim', type=int, default=128//4)\n",
    "parser.add_argument('--num_blstm_layers', type=int, default=24//4)\n",
    "parser.add_argument('--mlp_dim', type=int, default=512//2)\n",
    "parser.add_argument('--batch_size', type=int, default=95)\n",
    "parser.add_argument('--clip_grad_norm', type=int, default=5)\n",
    "parser.add_argument('--max_epochs', type=int, default=500)\n",
    "parser.add_argument('--portion', type=float, default=1.0)\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "\n",
    "parser.add_argument('--musdbhq_location', type=str, default=\"/home/sahand/BandSplit-RNN/musdb18hq/\")\n",
    "parser.add_argument('--checkpoint_fp', type=str, default=\"./checkpoint_100_v7.pt\")\n",
    "parser.add_argument('--mode', type=str, default='transfer') # \"train-base-model,transfer,infer\"\n",
    "parser.add_argument('--part', type=str, default=\"other\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "fg_generic_bands = args.generic_bands == \"Y\"\n",
    "sample_rate = args.sample_rate\n",
    "chunk_size_in_seconds = args.chunk_size_in_seconds\n",
    "chunk_size = chunk_size_in_seconds * sample_rate\n",
    "n_fft = args.n_fft\n",
    "win_length = n_fft\n",
    "hop_length = win_length // 4\n",
    "feature_dim = args.feature_dim\n",
    "num_blstm_layers= args.num_blstm_layers\n",
    "mlp_dim = args.mlp_dim\n",
    "max_epochs = args.max_epochs\n",
    "transfer_learning = args.mode == \"transfer\"\n",
    "batch_size = args.batch_size\n",
    "clip_grad_norm = args.clip_grad_norm\n",
    "portion = args.portion\n",
    "musdbhq_location = args.musdbhq_location\n",
    "checkpoint_fp = args.checkpoint_fp\n",
    "lr=args.lr\n",
    "inference= args.mode == \"infer\"\n",
    "train_base_model = args.mode == \"train-base-model\"\n",
    "part = args.part\n",
    "\n",
    "#~~~~Setup random generators~~~~\n",
    "# TODO: from arg\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "#~~~~Pre-process and Post-process utils~~~~\n",
    "\n",
    "def show_idp_audio(waveform):\n",
    "    import IPython.display as idp\n",
    "    n = 14\n",
    "    return idp.display(idp.Audio(waveform[(3 * n) * sample_rate:(3 * (n + 1)) * sample_rate], rate=sample_rate))\n",
    "\n",
    "def load_audio(path, visualize=False):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    # Convert everthing to mono channel for simplicity\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        # waveform is now a vector \n",
    "    # Resample everything to 44.1khz for simplicity\n",
    "    resampler = T.Resample(sr, sample_rate, dtype=waveform.dtype)\n",
    "    waveform = resampler(waveform)\n",
    "    \n",
    "    if visualize:\n",
    "        # samplerate = 1/t\n",
    "        # display the first 3 seconds\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "def rms_normalize(waveform, target_rms):\n",
    "    current_rms = torch.sqrt(torch.mean(waveform**2))\n",
    "    gain_factor = target_rms / (current_rms + 1e-10)\n",
    "    normalized_waveform = waveform * gain_factor\n",
    "    return normalized_waveform, gain_factor\n",
    "\n",
    "def rms_denormalize(normalized_waveform, gain_factor):\n",
    "    inverse_gain = 1 / gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def peak_normalize(waveform, target_peak):\n",
    "    peak_value = torch.max(torch.abs(waveform))\n",
    "    peak_gain_factor = target_peak / (peak_value + 1e-10)\n",
    "    normalized_waveform = waveform * peak_gain_factor\n",
    "    return normalized_waveform, peak_gain_factor\n",
    "\n",
    "def peak_denormalize(normalized_waveform, peak_gain_factor):\n",
    "    inverse_peak_gain = 1 / peak_gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_peak_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def inspect_waveform(waveform):\n",
    "    transform = T.Loudness(sample_rate)\n",
    "    return f\"LKFS:{transform(waveform.unsqueeze(0))} max: {waveform.max()} min: {waveform.min()} avg: {waveform.mean()}\"\n",
    "\n",
    "def normalize_waveform(waveform, visualize=False):\n",
    "    \"\"\" rms -> peak \"\"\"\n",
    "    # target rms can be anything. the important part here\n",
    "    # is to be constant for all kind of songs\n",
    "\n",
    "    if visualize:\n",
    "        print(\"original: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "\n",
    "    normalized_waveform, gain_factor = rms_normalize(waveform, target_rms=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "\n",
    "    # setting target peak to 1.0 forces the values between -1.0 < y < 1.0\n",
    "    normalized_waveform, peak_gain_factor = peak_normalize(normalized_waveform, target_peak=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "    \n",
    "    return normalized_waveform, gain_factor, peak_gain_factor\n",
    "\n",
    "def de_normalize_waveform(waveform, gain_factor, peak_gain_factor, visualize=False):\n",
    "    if visualize:\n",
    "        print(\"de_normalize_waveform: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    waveform = peak_denormalize(waveform, peak_gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    waveform = rms_denormalize(waveform, gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "def split(waveform, visualize=False, drop_last=False):\n",
    "    # we have a vector by length n and we want to split it to even chunks by length of\n",
    "    # chunk_size\n",
    "    padding_length = (chunk_size - waveform.shape[0] % chunk_size) % chunk_size\n",
    "    waveform = nn.functional.pad(waveform, (0, padding_length), 'constant', 0)\n",
    "    # -1 means automatically infer based on other dims\n",
    "    chunked_waveform = waveform.view(-1, chunk_size)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(16, 4))\n",
    "        subfigs = fig.subfigures(2, 1).flat\n",
    "        \n",
    "        # first 3 chunk_size of waveform\n",
    "        w = waveform[:3 * chunk_size].detach().numpy()\n",
    "        ylim = [w.max() * 1.1, w.min() * 1.1]\n",
    "        def time_axis(start, duration):\n",
    "            return torch.arange(start * sample_rate, (duration + start) * sample_rate) / sample_rate\n",
    "        axes = subfigs[0].subplots(1, 1)\n",
    "        axes.plot(time_axis(0, 3), w, linewidth=0.3)\n",
    "        axes.set_xlabel(\"time [s] for first 3 seconds\")\n",
    "        axes.set_ylim(ylim)\n",
    "        \n",
    "        # first 4 chunks + last chunk\n",
    "        axes = subfigs[1].subplots(1, 5)\n",
    "        for i, chunk in enumerate([0, 1, 3, 4, chunked_waveform.shape[0] - 1]): \n",
    "            axes[i].plot(time_axis(0, chunk_size_in_seconds), chunked_waveform[chunk], linewidth=0.3)\n",
    "            axes[i].set_title(f\"chunk {chunk}\")\n",
    "            axes[i].set_ylim(ylim)\n",
    "    if drop_last:\n",
    "        return chunked_waveform[:-1], 0\n",
    "    return chunked_waveform, padding_length\n",
    "\n",
    "def merge(chunks, padding_length):\n",
    "    merged_waveform = torch.cat([torch.flatten(x) for x in chunks])\n",
    "    return merged_waveform[:-padding_length]\n",
    "\n",
    "def visualize_spectogram(chunk, chunk_stft, title='Spectogram'):\n",
    "    import librosa\n",
    "    fig, axis = plt.subplots(2, 1, figsize=(16, 5))\n",
    "    noverlap = win_length - hop_length\n",
    "    axis[0].imshow(librosa.power_to_db(chunk_stft.abs().detach().numpy() ** 2),\\\n",
    "                   origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    axis[0].set_yscale(\"symlog\")\n",
    "    axis[0].set_title(title)\n",
    "    if chunk is not None:\n",
    "        axis[1].plot(chunk, linewidth=0.5)\n",
    "        axis[1].grid(True)\n",
    "        axis[1].set_xlim([0, len(chunk)])\n",
    "\n",
    "def to_spectogram():\n",
    "    transform_spectogram = T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                         window_fn=torch.hamming_window, power=None)\n",
    "    def inner(chunk, visualize=False, title=''):\n",
    "        chunk_stft = transform_spectogram(chunk)\n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk, chunk_stft, title)\n",
    "\n",
    "        return chunk_stft\n",
    "    return inner\n",
    "\n",
    "def from_spectogram():\n",
    "    transform_inv_spectogram = T.InverseSpectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                                    window_fn=torch.hamming_window)\n",
    "\n",
    "    def inner(chunk_stft, visualize=False):\n",
    "        chunk = transform_inv_spectogram(chunk_stft)\n",
    "    \n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk.detach().numpy(), chunk_stft)\n",
    "\n",
    "        return chunk\n",
    "    return inner\n",
    "\n",
    "class Vis:\n",
    "    \"\"\" Generate model's visual graph \"\"\"\n",
    "    def visualize(self, input):\n",
    "        from torchview import draw_graph\n",
    "        y = self(input)\n",
    "        x = draw_graph(self, input_data=input, device='meta', roll=True)\n",
    "        print(f\"--{input.shape}-->f(x)--{y.shape}-->\")\n",
    "        file = x.visual_graph.render(self._get_name())\n",
    "        display(idp.FileLink(\"./\" + file))\n",
    "\n",
    "        \n",
    "def get_microtone_name(semitones_from_A4, divisions_per_octave):\n",
    "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "    microtone_index = int((semitones_from_A4 + 9) * divisions_per_octave / 12) % divisions_per_octave\n",
    "    octave = int((semitones_from_A4 + 9) // 12)\n",
    "    note_index = microtone_index // (divisions_per_octave // 12)\n",
    "    microtone_suffix = f\"+{microtone_index % (divisions_per_octave // 12)}\"\n",
    "    return notes[note_index] + (microtone_suffix if microtone_suffix != \"+0\" else \"\") + str(octave)\n",
    "\n",
    "def microtonal_notes(divisions_per_octave):\n",
    "    A4_freq = 440.0\n",
    "    min_freq = 20.0\n",
    "    max_freq = 20000.0\n",
    "    notes = []\n",
    "    freqs = []\n",
    "    current_freq = min_freq\n",
    "    while current_freq <= max_freq:\n",
    "        semitones_from_A4 = 12 * np.log2(current_freq / A4_freq)\n",
    "        nearest_microtone = round(semitones_from_A4 * divisions_per_octave / 12)\n",
    "        nearest_freq = A4_freq * (2 ** (nearest_microtone / divisions_per_octave))\n",
    "\n",
    "        # Check if the frequency is a microtonal (not a standard semitone)\n",
    "        if nearest_microtone % (divisions_per_octave // 12) != 0:\n",
    "            note_name = get_microtone_name(nearest_microtone / (divisions_per_octave / 12), divisions_per_octave)\n",
    "            notes.append(note_name)\n",
    "            freqs.append(nearest_freq)\n",
    "\n",
    "        # Move to the next microtone\n",
    "        current_freq = A4_freq * (2 ** ((nearest_microtone + 1) / divisions_per_octave))\n",
    "    return (notes, freqs)\n",
    "\n",
    "def plot_custom_labeled_attention_distribution(splits):\n",
    "    start_freq = 0\n",
    "    events = []\n",
    "    for end_freq, step_size in splits:\n",
    "        while start_freq < end_freq:\n",
    "            start_freq += step_size\n",
    "            events.append(start_freq)\n",
    "\n",
    "    notes, positions = microtonal_notes(24)\n",
    "    print(len(events))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks(positions, notes, rotation=90, fontsize=9)\n",
    "    plt.eventplot(events, orientation='horizontal', colors='b')\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def evenly_skip_elements(input_list, k):\n",
    "    step = len(input_list) / k\n",
    "    new_list = [input_list[int(i * step)] for i in range(k)]\n",
    "\n",
    "    return new_list\n",
    "\n",
    "def create_evenly_distributed_splits(num_splits):\n",
    "    _, freqs = microtonal_notes(24)\n",
    "    splits = []\n",
    "    last_freq = 0\n",
    "    for freq in evenly_skip_elements(freqs, num_splits):\n",
    "        splits.append((freq, freq - last_freq))\n",
    "        last_freq = freq\n",
    "    return splits\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#~~~~Model definition~~~~\n",
    "\n",
    "# Numbers are exctracted from the paper\n",
    "splits_generic = create_evenly_distributed_splits(41)\n",
    "splits_v7 = [\n",
    "   # below 1kh, bandwidth 100hz\n",
    "   (1000, 100),\n",
    "   # above 1kh and below 4khz, bandwidth 250hz\n",
    "   (4000, 250),\n",
    "   (8000, 500),\n",
    "   (16000, 1000),\n",
    "   (20000, 2000),\n",
    "]\n",
    "\n",
    "#~~~~Module 1\n",
    "\n",
    "temporal_dim = int(np.ceil(chunk_size / T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length).hop_length))\n",
    "\n",
    "class BandSplit(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, splits=splits_generic if fg_generic_bands else splits_v7, fully_connected_out=feature_dim):\n",
    "        super(BandSplit, self).__init__()\n",
    "\n",
    "        #### Make splits\n",
    "        # convert fft to freq\n",
    "        freqs = sample_rate * torch.fft.fftfreq(n_fft)[:n_fft // 2 + 1]\n",
    "        freqs[-1] = sample_rate // 2\n",
    "        indices = []\n",
    "        start_freq, start_index = 0, 0\n",
    "        for end_freq, step in splits:\n",
    "            bands = torch.arange(start_freq + step, end_freq + step, step)\n",
    "            start_freq = end_freq\n",
    "            for band in bands:\n",
    "                end_index = freqs[freqs < band].shape[0]\n",
    "                if end_index != start_index or not fg_generic_bands:\n",
    "                    indices.append((start_index, end_index))\n",
    "                start_index = end_index\n",
    "        indices.append((start_index, freqs.shape[0]))\n",
    "        self.band_indices = indices\n",
    "        self.fully_connected_out = fully_connected_out\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.LayerNorm([(band_end - band_start) * 2, temporal_dim])\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "        \n",
    "        self.layer_fcs =  nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.Linear((band_end - band_start) * 2, self.fully_connected_out)\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "\n",
    "    def forward(self, chunk_ftt):\n",
    "        batch_size = chunk_ftt.size(0)\n",
    "        stack = []\n",
    "        # TODO: can i vectorize this loop?\n",
    "        for i, (band_start, band_end) in enumerate(self.band_indices):\n",
    "            band = chunk_ftt[:, band_start:band_end, :]\n",
    "            # band is shape of (B, F, T)\n",
    "            band = torch.view_as_real(band) # (B, F, T, 2)\n",
    "            # convert to (B, 2, F, T) to be able to feed it to the norm\n",
    "            band = band.permute(0, 3, 1, 2)\n",
    "            \n",
    "            # norm is (..., F, T) and fc is (Fxfully_connected_out)\n",
    "            # we should make norm (..., T, F) in order to feed it to the fc\n",
    "            band = band.reshape(batch_size, -1, band.size(-1)) # -1 = T\n",
    "            norm = self.layer_norms[i](band)\n",
    "            \n",
    "            norm = norm.transpose(-1, -2).contiguous()\n",
    "            fc_y = self.layer_fcs[i](norm)\n",
    "            \n",
    "            stack.append(fc_y)\n",
    "        return torch.stack(stack, dim=1)\n",
    "\n",
    "#~~~~Module 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_dim_size = input_dim_size\n",
    "        # paper specified group norm\n",
    "        self.norm = nn.ModuleList([nn.GroupNorm(self.input_dim_size, self.input_dim_size) for _ in range(2)])\n",
    "        self.blstm = nn.ModuleList([nn.LSTM(self.input_dim_size, self.input_dim_size,\\\n",
    "                                            bidirectional=True, batch_first=True) for _ in range(2)])\n",
    "        self.fc = nn.ModuleList([nn.Linear(self.input_dim_size * 2, self.input_dim_size) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input is b, bands(K), temporal_dim(t), input_dim_size\n",
    "        \n",
    "        \n",
    "        # First loops converts the shape to [B, T, K, N]\n",
    "        # and the second loop converts it back to [B, K, T, N]\n",
    "        for i in range(2):\n",
    "            B, K, T, N = x.shape\n",
    "            out = x.view(B * K, T, N)\n",
    "            out = self.norm[i](out.transpose(-1, -2)).transpose(-1, -2)\n",
    "            out = self.blstm[i](out)[0]\n",
    "            out = self.fc[i](out)\n",
    "            x = out.view(B, K, T, N) + x\n",
    "            x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class BandSequence(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, input_dim_size, num_layers=num_blstm_layers):\n",
    "        super(BandSequence, self).__init__()\n",
    "        self.rnns = nn.Sequential(*[RNN(input_dim_size=input_dim_size) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (bands, temporal_dim, fc_out)\n",
    "        return self.rnns(x)\n",
    "\n",
    "#~~~~Module 3    \n",
    "\n",
    "class MaskEstimation(nn.Module, Vis):\n",
    "    def __init__(self, band_indices, fully_connected_out):\n",
    "        super(MaskEstimation, self).__init__()\n",
    "        \n",
    "        max_indice_diff = max([e - s for s, e in band_indices])\n",
    "        num_hiddens = lambda e, s: 3 * (max_indice_diff - (e - s) + 1)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm([temporal_dim, fully_connected_out]),\n",
    "                nn.Linear(fully_connected_out, mlp_dim),\n",
    "                nn.Tanh(),\n",
    "                # double the output dim to use in GLU\n",
    "                # the extra *2 is for returning as complex\n",
    "                nn.Linear(mlp_dim, (e - s) * 2 * 2),\n",
    "                nn.GLU()\n",
    "            )\n",
    "            for s, e in band_indices\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (b, k, temporal_dim, fc_out)\n",
    "        parts = []\n",
    "        for i in range(x.shape[1]):\n",
    "            y = self.layers[i](x[:, i]).contiguous()\n",
    "            B, T, F = y.shape\n",
    "            y = y.permute(0, 2, 1).contiguous() # B F T\n",
    "            # basically halve the freq dim and use it for phasee\n",
    "            y = y.view(B, 2, F // 2, T) # (B, 2, F, T)\n",
    "            y = y.permute(0, 2, 3, 1) # (B, F, T, 2)\n",
    "            y = torch.view_as_complex(y.contiguous())\n",
    "            \n",
    "            parts.append(y)\n",
    "        \n",
    "        # (b, f, t)\n",
    "        return torch.cat(parts, dim=-2)\n",
    "    \n",
    "\n",
    "#~~~~Module BSRNN\n",
    "\n",
    "# Putting everything together!\n",
    "\n",
    "class BSRNN(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, num_sources=1):\n",
    "        super(BSRNN, self).__init__()\n",
    "        \n",
    "        self.split = BandSplit()\n",
    "        self.sequence = BandSequence(input_dim_size=self.split.fully_connected_out)\n",
    "        \n",
    "        self.masks = nn.ModuleList([MaskEstimation(band_indices=self.split.band_indices, \n",
    "                                                    fully_connected_out=self.split.fully_connected_out) \n",
    "                                    for _ in range(num_sources)])\n",
    "\n",
    "    def forward(self, chunk_fft):\n",
    "        \n",
    "        mean = chunk_fft.mean(dim=(1, 2), keepdim=True)\n",
    "        std = chunk_fft.std(dim=(1, 2), keepdim=True)\n",
    "        chunk_fft = (chunk_fft - mean) / (std + 1e-5)\n",
    "        \n",
    "        y = self.split(chunk_fft)\n",
    "        y = self.sequence(y)\n",
    "        masks = torch.stack([mask(y) for mask in self.masks], dim=0)\n",
    "        \n",
    "        masks = (masks * std) + mean\n",
    "\n",
    "        return masks\n",
    "\n",
    "class MSSBandSplitRNN(nn.Module, Vis):\n",
    "    def __init__(self):\n",
    "        super(MSSBandSplitRNN, self).__init__()\n",
    "        self.to_spectogram = to_spectogram()\n",
    "        self.from_spectogram = from_spectogram()\n",
    "        self.bsrnn = BSRNN()\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        \"\"\" Waveform in -> Waveform out :) \"\"\"\n",
    "        \n",
    "        # 1) normalize\n",
    "        # 2) split\n",
    "        # 3) feed to bsrnn\n",
    "        # 4) convert spectogram to audio\n",
    "        # 5) merge all splits\n",
    "        # 6) de-normalize\n",
    "        \n",
    "        normal_waveform, gain_factor, peak_gain_factor = normalize_waveform(waveform)\n",
    "        splits, padding_length = split(normal_waveform)\n",
    "        masked_splits = [[] for _ in range(len(splits))]\n",
    "        for i, x_split in enumerate(splits):\n",
    "            split_stft = self.to_spectogram(x_split)\n",
    "            masks = self.bsrnn(split_stft.unsqueeze(0))[0]\n",
    "            \n",
    "            for source in masks:\n",
    "                wave = self.from_spectogram(masked_complex)\n",
    "                masked_splits[i].append(wave)\n",
    "        \n",
    "        sources = []\n",
    "        for masked_splits_in_source in zip(*masked_splits):\n",
    "            sources.append(masked_splits_in_source)\n",
    "        \n",
    "        masked_waveforms = [merge(x, padding_length) for x in sources]\n",
    "        y = [de_normalize_waveform(x, gain_factor, peak_gain_factor) in masked_waveforms]\n",
    "        return y\n",
    "    \n",
    "\n",
    "#~~~~Training\n",
    "\n",
    "#~~Loss,Eval\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mae_stft_real = nn.L1Loss()\n",
    "        self.mae_stft_imag = nn.L1Loss()\n",
    "        self.mae_inv_stft  = nn.L1Loss()\n",
    "    \n",
    "    def forward(self, pred_stft, target_stft,  pred_inv_stft, target_inv_stft):\n",
    "        loss_r = self.mae_stft_real(pred_stft.real, target_stft.real)\n",
    "        loss_i = self.mae_stft_imag(pred_stft.imag, target_stft.imag)\n",
    "        loss_t = self.mae_inv_stft(pred_inv_stft, target_inv_stft)\n",
    "        loss = loss_r + loss_i + loss_t\n",
    "        return loss\n",
    "\n",
    "def compute_usdr(pred, target, delta = 1e-7):\n",
    "    if pred.shape[0] < target.shape[0]:\n",
    "        padding = target.shape[0] - pred.shape[0]\n",
    "        pred = torch.nn.functional.pad(pred, (0, padding), \"constant\", 0)\n",
    "    num = torch.sum(torch.square(target))\n",
    "    den = torch.sum(torch.square(target - pred))\n",
    "    num += delta\n",
    "    den += delta\n",
    "    usdr = 10 * torch.log10(num / den)\n",
    "    return usdr.mean()\n",
    "\n",
    "#~~Dataloader\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "all_parts = [\"bass\", \"drums\", \"other\", \"vocals\"]\n",
    "\n",
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, parts=all_parts, dir_=musdbhq_location, validation=False, portion=1):\n",
    "        super(Dataset, self).__init__()\n",
    "        path = dir_ + (\"test\" if validation else \"train\")\n",
    "        self.parts = parts\n",
    "        self.files = [entry for entry in os.scandir(path) if entry.is_dir()]\n",
    "        random.shuffle(self.files) # we are seeding the random gen manually so this is fine.\n",
    "        self.files = self.files[:int(len(self.files) * portion)]\n",
    "        self.loaded = {}\n",
    "        torch.set_default_device('cpu')\n",
    "        self.to_stft = to_spectogram()\n",
    "        print(\"pre-loading\")\n",
    "        targets = [f\"{d.path}/{part}.wav\" for part in self.parts for d in self.files]\n",
    "        [targets.append(f\"{d.path}/mixture.wav\") for d in self.files]\n",
    "        from tqdm import tqdm\n",
    "        self.cache = True\n",
    "        for x in tqdm(targets[:int(len(targets) * 0.2)]):\n",
    "            self.load_audio(x)\n",
    "        self.cache = False\n",
    "        print(\"pre-loading done\")\n",
    "\n",
    "    def load_audio(self, path):\n",
    "        if path in self.loaded:\n",
    "            return self.loaded[path]\n",
    "        x = load_audio(path)\n",
    "        x, _, _ = normalize_waveform(x)\n",
    "        x, _ = split(x, drop_last=True)\n",
    "        x = torch.stack([self.to_stft(k) for k in x], dim=0)\n",
    "        if self.cache:\n",
    "            self.loaded[path] = x\n",
    "        return x\n",
    "    \n",
    "    def iterator(self):\n",
    "        torch.set_default_device('cpu')\n",
    "        \n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            d = self.files[i]\n",
    "            \n",
    "            mixture = f\"{d.path}/mixture.wav\"\n",
    "            targets = [f\"{d.path}/{part}.wav\" for part in self.parts]\n",
    "            \n",
    "            mix_stft_splits = self.load_audio(mixture)\n",
    "            target_stfts_splits = [self.load_audio(target) for target in targets]\n",
    "            \n",
    "            for i, mix_stft in enumerate(mix_stft_splits):\n",
    "                target_stfts = [x[i] for x in target_stfts_splits]\n",
    "                out = (d.path, mix_stft, target_stfts)\n",
    "                yield out\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is not None:\n",
    "            total_files = len(self.files)\n",
    "            per_worker = int(math.ceil(total_files / float(worker_info.num_workers)))\n",
    "            self.start_index = worker_info.id * per_worker\n",
    "            self.end_index = min(self.start_index + per_worker, total_files)\n",
    "        else:\n",
    "            self.start_index = 0\n",
    "            self.end_index = len(self.files)\n",
    "\n",
    "        return iter(self.iterator())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17852d50-744a-45a0-b8e0-859ab87d26b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 40/40 [00:08<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-loading done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_workers=1\n",
    "parts = all_parts if train_base_model else [part]\n",
    "t_dataset = Dataset(validation=False, parts=parts, portion=portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d99b271-2697-42ff-a69a-adc6a1b90cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2903374b-d4b3-437e-a40c-8082336748c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-loading done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "v_dataset = Dataset(validation=True, parts=parts, portion=portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0faf98d-6bf4-4079-8c1e-dbabd2f55a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# del val_loader\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a019b1a-1821-4014-8086-6f5109050836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run name=./train-logs/v7-split-base-model-to-other-portion-1.0-2023-12-31 09:19:13.619384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 09:19:14.856442: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-31 09:19:14.856488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-31 09:19:14.904089: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-31 09:19:14.987487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-31 09:19:15.740573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params checkpoint -> 7165516\n",
      "Params before freeze -> 3908804\n",
      "Params after freeze -> 3256712\n",
      "Parameter count 3256712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9076a6e6474c0e9953dc60fe7dabc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.518299051845583 - iter_timer:0.4601980713928576s - epoch_timer:86.03973988199999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28ce159b5f3478c8992262b11b421f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.5104394953976972 - iter_timer:0.5063302144583341s - epoch_timer:713.645084088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cad5a57cc0411999cf6d25c243ff7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.468884954079254 - iter_timer:0.4873686691706345s - epoch_timer:820.225246547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e5f85a128444b5942c4535b7b50a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.446528833118063 - iter_timer:0.49722021642856973s - epoch_timer:490.53349423199984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c617254bf44611b0137f0df6115e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.4302771602261568 - iter_timer:0.49887206570952314s - epoch_timer:838.2567309730002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2082bc0d0c264441a60e4b9c8e977897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.4176169815290416 - iter_timer:0.49116841551190793s - epoch_timer:366.30816641599995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96e71e69a04416e8d288028da27ca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.4076091380566471 - iter_timer:0.48417956692687725s - epoch_timer:1499.960042092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce0bb9d244a4a71972aadd6647846e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3995235409062734 - iter_timer:0.4858013916384011s - epoch_timer:681.9865483009999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1377dd16df6e48f0adad37d2948c8518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3928725040885266 - iter_timer:0.4843872834087409s - epoch_timer:759.9783361419995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a955c4581ad74c91993184cf3fd072b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3871870935432962 - iter_timer:0.48113185733096925s - epoch_timer:397.1247930769996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de0f84283f4417691b303bc7ec87834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.382412024188138 - iter_timer:0.48673433428139906s - epoch_timer:979.0251300479995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db36337862104e5facddc7909c6da9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3783458594827556 - iter_timer:0.4879834733006088s - epoch_timer:940.1754153399997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe496fe79bd44f2937a7781124f74ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.37478196426142 - iter_timer:0.4912094974432427s - epoch_timer:442.9373799059995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2bd621e9ef40049484f4268185606c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3716926317877678 - iter_timer:0.48971786737331824s - epoch_timer:562.2797252260007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a54c9ac7f5e49f1a0970793ce581c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3690017461749275 - iter_timer:0.4875709003476329s - epoch_timer:737.9010065950006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ae60339525439ca2224ee3b7c3514f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3665910708656457 - iter_timer:0.48468096218304607s - epoch_timer:574.150707625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f89b25520a848b9962ff1af044c61ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f0405e11d14b898a421bd0eac0f4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.364475787015491 - iter_timer:0.4819990680833466s - epoch_timer:1301.2869623940005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561ca499be72453eb391ce8f541019c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2762207fa01444ab8d656b91d79540f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3626741991925915 - iter_timer:0.48109283678837306s - epoch_timer:922.4119446650002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a248d98716840ea96254e7212a0ee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ec996b8b7c40e6a5c6abd776c6b21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3610081059997508 - iter_timer:0.48099916315665386s - epoch_timer:844.598151061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2325463bde4488af7b91c020b9101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796c14b7d2f24240ace2f23c37dc43a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3595655319639133 - iter_timer:0.4797772872863285s - epoch_timer:631.4146072269996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0ecc068c40409da0cc92f192ef2aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57eb65935a054b9a97baa0822424853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3582693962200125 - iter_timer:0.47865034713550986s - epoch_timer:1188.819473607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7017dfb2b9fc4f66a12dac11af7ce406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67af0586fa1e4b408fc4245dc34cef2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.357131916234004 - iter_timer:0.47862874122350424s - epoch_timer:680.2467598260009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e486da2016d349aca4f000a78f086e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1f703edd024278ba88270821181900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3560350969982433 - iter_timer:0.4774615485662643s - epoch_timer:1526.281234850001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea85dfe20da473dae0922851d45fa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg usdr: 1.3551197350583422 - iter_timer:0.47855622577480295s - epoch_timer:1662.564728409001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20f8a382c3c4544a27c7d3431af4314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/84]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 225\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Run Training\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter count \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount_parameters(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 225\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(prefix)    \n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:898\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:941\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:999\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:965\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 965\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:1038\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_STARTED)\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_COMPLETED)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# del trainer\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # (d.path, mix_stft (1025, 87), target_stfts (4, 1025, 87))\n",
    "    b_mix_stft = []\n",
    "    b_target_stfts = [[] for _ in range(len(batch[0][2]))]\n",
    "    \n",
    "    for x, mix, target in batch:\n",
    "        b_mix_stft.append(mix)\n",
    "        for i, t in enumerate(target):\n",
    "            b_target_stfts[i].append(t)\n",
    "    # (B, 1025, 87), (4, B, 1025, 87)\n",
    "    return torch.stack(b_mix_stft), [torch.stack(x) for x in b_target_stfts]\n",
    "\n",
    "batch_size = 270\n",
    "train_loader = torch.utils.data.DataLoader(t_dataset, num_workers=num_workers, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                          persistent_workers=True)\n",
    "val_loader   = torch.utils.data.DataLoader(v_dataset, num_workers=num_workers, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                          persistent_workers=True)\n",
    "\n",
    "\n",
    "# because we will load from base model in transfer learning\n",
    "model = BSRNN(num_sources=len(all_parts) if transfer_learning else len(parts)).to('cuda')\n",
    "import datetime\n",
    "\n",
    "fg_prefix = \"generic-split\" if fg_generic_bands else \"v7-split\"\n",
    "name_prefix = \"base-model\" if train_base_model else f\"base-model-to-{part}\"\n",
    "\n",
    "name = f\"{fg_prefix}-{name_prefix}-portion-{portion}\"\n",
    "prefix=f\"./train-logs/{name}-{datetime.datetime.now()}\"\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(prefix)\n",
    "print(f\"run name={prefix}\")\n",
    "\n",
    "\n",
    "#~~~~Train\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, Checkpoint, DiskSaver, global_step_from_engine\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine, TensorboardLogger\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.handlers import Timer\n",
    "#~~Ignite setup\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = CustomLoss()\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "inv_stft_gpu = from_spectogram()\n",
    "\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    # start = time.time()\n",
    "    model.train()\n",
    "    # print(f\"model.train(){time.time() - start}s\");start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    # print(f\"zero grad{time.time() - start}s\");start = time.time()\n",
    "    mix_stft, mask_stfts = batch\n",
    "    mix_stft, mask_stfts = mix_stft.to('cuda'), mask_stfts\n",
    "    mask_stfts = [x.to('cuda') for x in mask_stfts]\n",
    "    # print(f\"batch{time.time() - start}s\");start = time.time()\n",
    "    \n",
    "    y_masks = model(mix_stft) # (num_sources, B, 1025, 87)\n",
    "    # print(f\"ff{time.time() - start}s\");start = time.time()\n",
    "    inv_y_masks = [inv_stft_gpu(y_mask) for y_mask in y_masks]\n",
    "    # print(f\"inv{time.time() - start}s\");start = time.time()\n",
    "    # (num_sources, B, 1025, 87)\n",
    "    inv_mask_stfts = [inv_stft_gpu(mask_stft) for mask_stft in mask_stfts]\n",
    "    # print(f\"inv masks{time.time() - start}s\");start = time.time()\n",
    "    \n",
    "    total_loss = 0 # total loss for all heads\n",
    "    for y_mask, mask_stft, inv_y_mask, inv_mask_stft in zip(y_masks, mask_stfts, inv_y_masks, inv_mask_stfts):\n",
    "        total_loss += loss_fn(y_mask, mask_stft, inv_y_mask, inv_mask_stft)\n",
    "    # print(f\"loss{time.time() - start}s\");start = time.time()\n",
    "    total_loss.backward()\n",
    "    # print(f\"backward{time.time() - start}s\");start = time.time()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "    optimizer.step()\n",
    "    # print(f\"opt{time.time() - start}s\");start = time.time()\n",
    "    \n",
    "    usdr_values = [compute_usdr(inv_y_mask, inv_mask_stft).item() for \\\n",
    "                      inv_y_mask, inv_mask_stft in zip(inv_y_masks, inv_mask_stfts)]\n",
    "    # print(f\"score{time.time() - start}s\");start = time.time()\n",
    "    return {'loss': total_loss.item(), 'usdr': np.mean(usdr_values)}\n",
    "\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "running_avg_usdr = RunningAverage(output_transform=lambda x: x['usdr'])\n",
    "running_avg_usdr.attach(trainer, 'running_avg_usdr')\n",
    "running_avg_loss = RunningAverage(output_transform=lambda x: x['loss'])\n",
    "running_avg_loss.attach(trainer, 'running_avg_loss')\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir=f\"{prefix}/tb\")\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda x: {\"running_avg_loss\": trainer.state.metrics['running_avg_loss'], \n",
    "                                \"running_avg_usdr\": trainer.state.metrics['running_avg_usdr']}\n",
    ")\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mix_stft, mask_stfts = batch\n",
    "        mix_stft, mask_stfts = mix_stft.to('cuda'), mask_stfts\n",
    "        mask_stfts = [mask_stft.to('cuda') for mask_stft in mask_stfts]\n",
    "\n",
    "        y_masks = model(mix_stft)\n",
    "        inv_y_masks = [inv_stft_gpu(y_mask) for y_mask in y_masks]\n",
    "        inv_mask_stfts = [inv_stft_gpu(mask_stft) for mask_stft in mask_stfts]\n",
    "        \n",
    "        \n",
    "        usdr_values = [compute_usdr(inv_y_mask, inv_mask_stft).item() for \\\n",
    "                      inv_y_mask, inv_mask_stft in zip(inv_y_masks, inv_mask_stfts)]\n",
    "        \n",
    "        return {\"usdr\": np.mean(usdr_values)}\n",
    "\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "running_avg_usdr_eval = RunningAverage(output_transform=lambda x: x['usdr'])\n",
    "running_avg_usdr_eval.attach(evaluator, 'running_avg_usdr_eval')\n",
    "\n",
    "iter_timer = Timer(average=True)\n",
    "epoch_timer = Timer(average=False)\n",
    "\n",
    "@evaluator.on(Events.COMPLETED)\n",
    "def log_results(engine):\n",
    "    usdr = engine.state.metrics['running_avg_usdr_eval']\n",
    "    print(f\"Test Results - Avg usdr: {usdr} - iter_timer:{iter_timer.value()}s - epoch_timer:{epoch_timer.value()}\")\n",
    "\n",
    "bar = ProgressBar(persist=False)\n",
    "bar.attach(evaluator, metric_names=['running_avg_usdr_eval'])\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def train_epoch_completed(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    start = time.time()\n",
    "    evaluator.run(val_loader)\n",
    "    tb_logger.add_scalar(\"evaluation/running_avg_usdr_eval\", evaluator.state.metrics['running_avg_usdr_eval'], epoch)\n",
    "\n",
    "\n",
    "iter_timer.attach(\n",
    "    trainer,\n",
    "    start=Events.STARTED,\n",
    "    resume=Events.ITERATION_STARTED,\n",
    "    pause=Events.ITERATION_COMPLETED,\n",
    "    step=Events.ITERATION_COMPLETED\n",
    ")\n",
    "\n",
    "epoch_timer.attach(\n",
    "    trainer,\n",
    "    start=Events.EPOCH_STARTED,\n",
    "    step=Events.EPOCH_COMPLETED,\n",
    ")\n",
    "\n",
    "# Model Checkpointing\n",
    "to_save = {\n",
    "    'trainer': trainer,\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'running_avg_usdr': running_avg_usdr,\n",
    "    'running_avg_loss': running_avg_loss\n",
    "}\n",
    "checkpoint_handler = Checkpoint(\n",
    "    to_save,\n",
    "    DiskSaver(f'{prefix}/models', create_dir=True),\n",
    "    n_saved=25,\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler)\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.isfile(checkpoint_fp):\n",
    "    checkpoint = torch.load(checkpoint_fp)\n",
    "    Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
    "\n",
    "\n",
    "# Progress Bar\n",
    "\n",
    "if transfer_learning:\n",
    "    new_model = BSRNN(num_sources=1).to('cuda')\n",
    "    print(f\"Params checkpoint -> {count_parameters(model)}\")\n",
    "    new_model.split = model.split\n",
    "    new_model.sequence = model.sequence\n",
    "    new_model.mask = nn.ModuleList([MaskEstimation(\n",
    "     band_indices=new_model.split.band_indices, \n",
    "     fully_connected_out=new_model.split.fully_connected_out   \n",
    "    )])\n",
    "    model = new_model\n",
    "    print(f\"Params before freeze -> {count_parameters(model)}\")\n",
    "    # Freeze first two modules. keep the mask estimation\n",
    "    for param in model.split.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.sequence.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.masks[0].parameters():\n",
    "        param.requires_grad = True\n",
    "    running_avg_usdr.reset()\n",
    "    running_avg_loss.reset()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    trainer.state.max_epochs = None\n",
    "    print(f\"Params after freeze -> {count_parameters(model)}\")\n",
    "\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=['running_avg_loss', 'running_avg_usdr'])\n",
    "# Run Training\n",
    "print(f\"Parameter count {count_parameters(model)}\")\n",
    "trainer.run(train_loader, max_epochs=max_epochs)\n",
    "print(prefix)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbd36e-1990-46fe-941d-a1de7ebc6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17552144\n",
    "#  7165516\n",
    "#  6997228"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bsrnn]",
   "language": "python",
   "name": "conda-env-bsrnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
